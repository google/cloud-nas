# Copyright 2020 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

train:
  # Train file pattern is provided by the binary flag.

  # Reduce the batch-size if you run into out-of-memory error.
  # Out-of-memory error may also be resolved by reducing
  # the image-size but at the expense of quality.
  # NOTE: 256 is for 4x4 TPU Pod. May need to adjust batch size and learning rate for 2x2 or GPU devices.
  train_batch_size: 128

  # Set num-steps to around 200 epochs.
  total_steps: 185200

  learning_rate:
    type: 'step'
    warmup_learning_rate: 0.0067
    warmup_steps: 2000
    # Reduce the learning rate if you get gradients reaching NAN error.
    init_learning_rate: 0.28
    learning_rate_levels: [0.028, 0.0028, 0.00028]
    learning_rate_steps: [166680, 175940, 180570]
  checkpoint:
    path: ''
    prefix: ''
  l2_weight_decay: 0.00004
  gradient_clip_norm: 10.0

eval:
  # Eval file pattern is provided by the binary flag.

  # Setting 'eval_samples' to null forces all the evaluation examples to be used.
  # Setting 'eval_samples: 5000' will use only 5000 examples.
  eval_samples: null

  # NOTE: Partial batch will not be used for evaluation. So ideally,
  # the total-number of eval-samples should be divisible by
  # 'eval_batch_size' if you want all the samples to be used.
  # 'eval_batch_size' needs to be divisible by 8 when using TPU.
  eval_batch_size: 8

architecture:
  backbone: 'tunable_spinenet'
  # NOTE: If you change the 'min_level' and 'max_level'
  # search-space related parameters here, then you also need
  # to change them in the 'search_spaces.py' file.
  min_level: 3
  max_level: 7
  multilevel_features: 'identity'
  # Note that `num_classes` is the total number of classes including
  # one background class with an index value of 0.
  num_classes: 91

anchor:
  # The intermediate scales added on each level.
  # For instance, num_scales=2 adds one additional intermediate anchor scales
  # [2^0, 2^0.5] on each level.
  num_scales: 3
  aspect_ratios: [1.0, 2.0, 0.5]
  # A float number representing the scale of size of the base
  # anchor to the feature stride 2^level.
  anchor_size: 3.0

batch_norm_activation:
  activation: 'swish'
  batch_norm_epsilon: 0.001
  batch_norm_momentum: 0.997
  batch_norm_trainable: True
  use_sync_bn: True

retinanet_head:
  # This number should be the same as anchor.num_scales * len(anchor.aspect_ratios).
  anchors_per_location: 9
  num_filters: 256
  use_separable_conv: False
  num_convs: 4

tunable_spinenet:
  ##### SpineNet-49 @640,896 ####
  filter_size_scale: 1.0
  block_repeats: 1
  resample_alpha: 0.5
  endpoints_num_filters: 256
  ##### SpineNet-96 @1024 #######
  # filter_size_scale: 1.0
  # block_repeats: 2
  # resample_alpha: 0.5
  # endpoints_num_filters: 256
  ##### SpineNet-143 @1280 ######
  # filter_size_scale: 1.0
  # block_repeats: 3
  # resample_alpha: 1.0
  # endpoints_num_filters: 256
  ##### SpineNet-49S @640 #######
  # filter_size_scale: 0.75
  # block_repeats: 1
  # resample_alpha: 0.5
  # endpoints_num_filters: 128
  ###############################
  init_drop_connect_rate: 0.2

retinanet_parser:
  # Controls the effective image-size for training.
  output_size: [640, 640]
  aug_scale_min: 0.5
  aug_scale_max: 2.0
  # The maximum number of bboxes in one image.
  max_num_instances: 100
  aug_rand_hflip: True
